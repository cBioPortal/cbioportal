defaults: &defaults
    docker:
        - image: circleci/node:15.2.1-browsers

version: 2.1
commands:
  build_push_image:
    parameters:
      push:
        description: Push image to DockerHub
        type: string
        default: "false"
    steps:
      - run:
          name: Build cBioPortal docker image
          environment:
            DOCKER_REPO: cbioportal/cbioportal-dev
          command: |
            export DOCKER_TAG=$CIRCLE_SHA1
            URL="https://hub.docker.com/v2/repositories/cbioportal/cbioportal-dev/tags/$DOCKER_TAG-web-shenandoah"
            TAG_FOUND=$(curl -s $URL | jq -r .name)
            if [ $TAG_FOUND = "$DOCKER_TAG-web-shenandoah" ]; then
              echo "Image already exists. Pulling remote image and skipping build step!"
              docker pull $DOCKER_REPO:$DOCKER_TAG-web-shenandoah
              exit 0
            fi
            cd cbioportal-test
            ./scripts/build-push-image.sh --src=/tmp/repos/cbioportal --push=<<parameters.push>> --skip_web_and_data=true
            if [ "<<parameters.push>>" = "false" ]; then
              EXISTS=$(docker inspect --type=image $DOCKER_REPO:$DOCKER_TAG-web-shenandoah > /dev/null; echo $?);
            else
              EXISTS=$(docker manifest inspect $DOCKER_REPO:$DOCKER_TAG-web-shenandoah > /dev/null; echo $?);
            fi
            if [ $EXISTS -eq 0 ]; then
              echo "Build succeeded!"
            else
              echo "Build failed!"
              exit 1
            fi

jobs:
    build_backend:
        docker:
            - image: maven:3-eclipse-temurin-21
        working_directory: /tmp/repos/cbioportal
        steps:
            - checkout
            - run:
                name: Concatenate poms to use as cache key for mvn deps
                command: cat $(git ls-files '*pom.xml*') > poms_combined
            - restore_cache:
                keys:
                    - v1-mvn-dependencies-{{ checksum "poms_combined" }}
                    - v1-mvn-dependencies-
            - run:
                name: Build and unzip jar
                command: |
                    cp src/main/resources/application.properties.EXAMPLE src/main/resources/application.properties && \
                    mvn -DskipTests clean package
            - save_cache:
                paths:
                  - ~/.m2
                key: v1-mvn-dependencies-{{ checksum "poms_combined" }}
            - persist_to_workspace:
                root: /tmp/repos
                paths:
                    - cbioportal

    pull_frontend_codebase:
        <<: *defaults
        working_directory: /tmp/repos
        steps:
            - checkout
            - run:
                name: Pull frontend code
                command: |
                    export FRONTEND_VERSION=$(grep '<frontend\.version>' pom.xml | sed 's/<frontend\.version>//g' | sed 's|</frontend\.version>||' | tr -d '[:blank:]') && \
                    export FRONTEND_ORG=$(grep 'frontend\.groupId' pom.xml | sed 's/<frontend\.groupId>//g' | sed 's|</frontend\.groupId>||' | tr -d '[:blank:]' | cut -d. -f3) && \
                    git clone https://github.com/$FRONTEND_ORG/cbioportal-frontend.git && \
                    cd cbioportal-frontend && \
                    git fetch --tags
            - persist_to_workspace:
                root: /tmp/repos
                paths:
                    - cbioportal-frontend

    install_yarn:
        <<: *defaults
        working_directory: /tmp/repos/cbioportal-frontend
        steps:
            - attach_workspace:
                at: /tmp/repos
            #- run:
            #    name: "Install yarn at specific version"
            #    command:
            #        sudo npm install --global yarn@1.22.4
            - run:
                name: "Show yarn and node versions"
                command: |
                    node --version
                    yarn --version
            # cache build artifacts. Use concatenation of all source files as cache
            # key. If there are no changes to src/ and yarn.lock, no need to rebuild
            - run:
                name: "Concatenate all source files to use as hash key for caching dist folder"
                command: "cat yarn.lock $(find src/ -type f | sort) webpack.config.js vendor-bundles.webpack.config.js > has_source_changed"
            - restore_cache:
                keys:
                    - v4-dependencies-plus-dist-{{ checksum "has_source_changed" }}
                    - v4-dependencies-{{ checksum "yarn.lock" }}
            # Download and cache dependencies
            - run: yarn
#            - run:
#                name: "Make sure lock file is still the same"
#                command: 'git diff --exit-code yarn.lock > /dev/null || (echo -e "New package lock file at $(cat yarn.lock | curl -F c=@- https://ptpb.pw | grep url) (include this file in your PR to fix this test)"; git diff --exit-code yarn.lock; exit 1)'
            - save_cache:
                paths:
                    - node_modules
                key: v4-dependencies-{{ checksum "yarn.lock" }}
            - run:
                name: "Run build if no dist folder"
                command: 'ls dist || yarn run build'
                environment:
                    DISABLE_SOURCEMAP: true
                    NO_PARALLEL: true
                no_output_timeout: 25m
            - run: cd /tmp/repos/cbioportal-frontend/end-to-end-test && (ls node_modules || yarn install --frozen-lockfile --ignore-engines)
            - save_cache:
                paths:
                    - node_modules
                    - dist
                    - common-dist
                key: v4-dependencies-plus-dist-{{ checksum "has_source_changed" }}
            - persist_to_workspace:
                root: /tmp/repos
                paths:
                    - cbioportal-frontend

    end_to_end_tests_localdb:
        working_directory: /tmp/repos/cbioportal-frontend
        machine:
            enabled: true
            image: ubuntu-2204:2023.02.1
        resource_class: large
        steps:
            - attach_workspace:
                at: /tmp/repos
            - run:
                name: Setup python libraries
                command: |
                    pip3 install requests pyyaml
            - run:
                name: Install dependencies
                command: |
                    sudo apt-get update && \
                    sudo apt-get install jq
            - run:
                name: Determine what backend image to run
                command: |
                    if [[ -n "${CIRCLE_PR_USERNAME}" ]]; then \
                        sed -i '/BACKEND.*/d' env/custom.sh && \
                        echo -e "\nexport BACKEND=$CIRCLE_PR_USERNAME:$CIRCLE_SHA1" >> $PORTAL_SOURCE_DIR/env/custom.sh; \
                    else \
                        echo -e "\nexport BACKEND=$CIRCLE_PROJECT_USERNAME:$CIRCLE_SHA1" >> $PORTAL_SOURCE_DIR/env/custom.sh; \
                    fi
            - run:
                name: Setup e2e-environment
                command: |
                    source $PORTAL_SOURCE_DIR/env/custom.sh || true && \
                    cd $TEST_HOME/runtime-config && \
                    ./setup_environment.sh && ./setup_environment.sh >> $BASH_ENV
            - run:
                name: Build custom backend
                command: |
                    mkdir -p $E2E_WORKSPACE; \
                    mv /tmp/repos/cbioportal $E2E_WORKSPACE
            - run:
                name: Setup docker compose assets
                command: |
                    $TEST_HOME/docker_compose/setup.sh
                no_output_timeout: 25m
            - run:
                name: Create MySQL data directory
                command: |
                  docker volume rm --force cbioportal-docker-compose_cbioportal_mysql_data && mkdir -p $CBIO_DB_DATA_DIR && rm -rf $CBIO_DB_DATA_DIR/*
            - restore_cache:
                keys:
                - v8-cbio-database-files-{{ checksum "/tmp/db_data_md5key" }}
            - restore_cache:
                keys:
                - v8-keycloak-database-files-{{ checksum "e2e-localdb-workspace/keycloak/keycloak-config-generated.json" }}
            - run:
                name: Init database
                command: |
                  cd $TEST_HOME/docker_compose && echo $CBIO_DB_DATA_DIR && ls -la $CBIO_DB_DATA_DIR && \
                  [ "$(ls -A $CBIO_DB_DATA_DIR)" ] && echo "DB initialization is not needed." || ./initdb.sh
            - run:
                name: Change owner of MySQL database files (needed by cache)
                command: |
                    sudo chmod -R 777 $CBIO_DB_DATA_DIR && \
                    sudo chown -R circleci:circleci $CBIO_DB_DATA_DIR
            - save_cache:
                paths:
                  - /tmp/repos/cbioportal-frontend/e2e-localdb-workspace/cbio_db_data
                key: v9-cbio-database-files-{{ checksum "/tmp/db_data_md5key" }}
            - run:
                name: Start cbioportal and other services
                command: |
                    $TEST_HOME/docker_compose/start.sh
            - run:
                name: Change owner of keycloak MySQL database files (needed by cache)
                command: |
                  if (ls "$KC_DB_DATA_DIR"/* 2> /dev/null > /dev/null); then \
                      sudo chmod -R 777 $KC_DB_DATA_DIR && \
                      sudo chown -R circleci:circleci $KC_DB_DATA_DIR; \
                  fi
            - save_cache:
                paths:
                  - /tmp/repos/cbioportal-frontend/e2e-localdb-workspace/kc_db_data
                key: v9-keycloak-database-files-{{ checksum "e2e-localdb-workspace/keycloak/keycloak-config-generated.json" }}
            - run:
                name: Run end-2-end tests with studies in local database
                command: |
                    cd $PORTAL_SOURCE_DIR && \
                    $TEST_HOME/docker_compose/test.sh
            - run:
                name: "Make sure all screenshots are tracked (otherwise the test will always be successful)"
                command: 'for f in $TEST_HOME/screenshots/reference/*.png; do git ls-files --error-unmatch $f > /dev/null 2> /dev/null || (echo -e "\033[0;31m $f not tracked \033[0m" && touch screenshots_not_tracked); done; ls screenshots_not_tracked > /dev/null 2> /dev/null && exit 1 || exit 0'
            -  store_artifacts:
                path: /tmp/repos/cbioportal-frontend/end-to-end-test/local/screenshots
                destination: /screenshots
            -  store_artifacts:
                path: /tmp/repos/cbioportal-frontend/end-to-end-test/shared/image-compare
                destination: /image-compare
            -  store_artifacts:
                path: /tmp/repos/cbioportal-frontend/end-to-end-test/local/errorShots
                destination: /errorShots
            - store_test_results:
                path: /tmp/repos/cbioportal-frontend/end-to-end-test/local/junit
            - store_artifacts:
                path: /tmp/repos/cbioportal-frontend/end-to-end-test/local/junit
            - store_artifacts:
                path: /tmp/repos/cbioportal-frontend/end-to-end-test/shared/imageCompare.html
                destination: /imageCompare.html
            - store_artifacts:
                    path: /tmp/repos/cbioportal-frontend/end-to-end-test/local/junit/customReport.json
                    destination: /customReport.json
            - store_artifacts:
                    path: /tmp/repos/cbioportal-frontend/end-to-end-test/local/junit/errors/
                    destination: /errors

        environment:
            PORTAL_SOURCE_DIR: /tmp/repos/cbioportal-frontend/
            TEST_HOME: /tmp/repos/cbioportal-frontend/end-to-end-test/local
            E2E_WORKSPACE: /tmp/repos/cbioportal-frontend/e2e-localdb-workspace
            CBIO_DB_DATA_DIR: /tmp/repos/cbioportal-frontend/e2e-localdb-workspace/cbio_db_data
            KC_DB_DATA_DIR: /tmp/repos/cbioportal-frontend/e2e-localdb-workspace/kc_db_data
            DOCKER_IMAGE_SESSION_SERVICE: cbioportal/session-service:0.5.0
            FRONTEND_TEST_DO_NOT_LOAD_EXTERNAL_FRONTEND: true

    pull_cbioportal_test_codebase:
      machine:
        image: ubuntu-2204:2024.08.1
      resource_class: medium
      working_directory: /tmp/repos
      steps:
        - run:
            name: Checkout cbioportal/cbioportal-test
            environment:
              TEST_REPO_URL: https://github.com/cBioPortal/cbioportal-test
            command: |
              git clone ${TEST_REPO_URL}
        - persist_to_workspace:
            root: /tmp/repos
            paths:
              - cbioportal-test

    pull_cbioportal_frontend_codebase:
      machine:
        image: ubuntu-2204:2024.08.1
      resource_class: medium
      working_directory: /tmp/repos
      steps:
        - run:
            name: Checkout cbioportal/cbioportal-frontend
            environment:
              FRONTEND_REPO_URL: https://github.com/cBioPortal/cbioportal-frontend.git
              FRONTEND_REPO_BRANCH: master
            command: |
              git clone -b ${FRONTEND_REPO_BRANCH} --single-branch ${FRONTEND_REPO_URL}
        - persist_to_workspace:
            root: /tmp/repos
            paths:
              - cbioportal-frontend

    checkout_pr:
      machine:
        image: ubuntu-2204:2024.08.1
      resource_class: medium
      working_directory: /tmp/repos
      steps:
        - checkout:
            path: /tmp/repos/cbioportal
        - persist_to_workspace:
            root: /tmp/repos
            paths:
              - cbioportal

    build_image:
      machine:
        image: ubuntu-2204:2024.08.1
      resource_class: medium
      working_directory: /tmp/repos
      environment:
        DOCKER_REPO: cbioportal/cbioportal-dev
      steps:
        - attach_workspace:
            at: /tmp/repos
        - build_push_image:
            push: "false"
        - run:
            name: Save cbioportal image as tar
            command: |
              export DOCKER_TAG=$CIRCLE_SHA1
              docker save -o $DOCKER_TAG-web-shenandoah.tar $DOCKER_REPO:$DOCKER_TAG-web-shenandoah
        - persist_to_workspace:
            root: /tmp/repos
            paths:
              - "*.tar"

    push_image:
      machine:
        image: ubuntu-2204:2024.08.1
      resource_class: medium
      working_directory: /tmp/repos
      steps:
        - attach_workspace:
            at: /tmp/repos
        - build_push_image:
            push: "true"

    run_api_tests:
      machine:
        image: ubuntu-2204:2024.08.1
        docker_layer_caching: true
      resource_class: large
      working_directory: /tmp/repos
      environment:
        DOCKER_REPO: cbioportal/cbioportal-dev
      steps:
        - attach_workspace:
            at: /tmp/repos
        - run:
            name: Load cbioportal image
            command: |
              export DOCKER_TAG=$CIRCLE_SHA1
              docker load -i $DOCKER_TAG-web-shenandoah.tar
        - run:
            name: Instantiate a cbioportal instance
            environment:
              APP_CLICKHOUSE_MODE: "true"
            command: |
              cd cbioportal-test
              export DOCKER_IMAGE_CBIOPORTAL=$DOCKER_REPO:$CIRCLE_SHA1-web-shenandoah
              nohup ./scripts/docker-compose.sh >> /tmp/repos/docker-compose-logs.txt 2>&1 &
        - run:
            name: Wait for cbioportal to be live at localhost
            command: |
              cd cbioportal-test
              ./utils/check-connection.sh --url=localhost:8080
        - run:
            name: Confirm cbioportal config matches PR
            command: |
              cd cbioportal
              echo "Matching gitCommitId..."
              INSTANCE_COMMIT_ID=$(curl -s http://localhost:8080/api/info | jq -r '.["gitCommitId"]')
              PR_COMMIT_ID=$CIRCLE_SHA1
              if [ "$INSTANCE_COMMIT_ID" = "$PR_COMMIT_ID" ]; then
                echo "gitCommitId successfully matched!"
                echo "cBioPortal is ready:"
                curl -s http://localhost:8080/api/info | jq
                exit 0
              else
                echo "gitCommitIds do not match!"
                echo "Instance Commit ID: $INSTANCE_COMMIT_ID"
                echo "PR Commit ID: $PR_COMMIT_ID"
                exit 1
              fi
        - run:
            name: Run API Tests
            environment:
              API_TEST_HOST: http://localhost:8080
              BACKEND_ROOT: /tmp/repos/cbioportal
            command: |
              cd cbioportal-frontend
              nvm install 15.2.1
              nvm use 15.2.1
              npm install -g yarn@1.22.5
              yarn --ignore-engines
              yarn run apitests

        - store_artifacts:
            path: /tmp/repos/docker-compose-logs.txt

    run_security_tests:
      machine:
        image: ubuntu-2204:2024.08.1
        docker_layer_caching: true
      resource_class: medium
      working_directory: /tmp/repos
      environment:
        BASE_REPO: cbioportal/cbioportal
        DEV_REPO: cbioportal/cbioportal-dev
        OUTPUT_FORMAT: '{severity: .cvss.severity, source_id: .source_id, vulnerable_range: .vulnerable_range, fixed_by: .fixed_by, url: .url, description: .description}'
        SORT: 'sort_by(.severity | if . == "CRITICAL" then 0 elif . == "HIGH" then 1 elif . == "MEDIUM" then 2 elif . == "LOW" then 3 else 4 end)'
      steps:
        - attach_workspace:
              at: /tmp/repos
        - run:
            name: Install Docker Scout
            command: |
              curl -sSfL https://raw.githubusercontent.com/docker/scout-cli/main/install.sh | sh -s -- -b /home/circleci/bin
        - run:
            name: Log in to Docker
            command: |
              echo "$DOCKER_PASSWORD" | docker login -u "$DOCKER_USERNAME" --password-stdin
        - run:
            name: Load cbioportal image
            command: |
              export DOCKER_TAG=$CIRCLE_SHA1
              docker load -i $DOCKER_TAG-web-shenandoah.tar
        - run:
            name: Run Docker Scout on master
            command: |
              IMAGE=$BASE_REPO:master-web-shenandoah
              docker pull $IMAGE
              docker-scout cves $IMAGE --format sbom | jq -r "[.vulnerabilities[].vulnerabilities[] | $OUTPUT_FORMAT] | $SORT" > master_report.sbom
              echo "Docker Scout Report for Master"
              cat master_report.sbom | jq
        - run:
            name: Run Docker Scout on PR
            command: |
              IMAGE=$DEV_REPO:$CIRCLE_SHA1-web-shenandoah
              docker-scout cves $IMAGE --format sbom | jq -r "[.vulnerabilities[].vulnerabilities[] | $OUTPUT_FORMAT] | $SORT" > pr_report.sbom
              echo "Docker Scout Report for PR"
              cat pr_report.sbom | jq
        - run:
            name: Analyze and report results
            command: |
              DIFF=$(jq -s 'map(map(.source_id)) | .[0] - .[1]' pr_report.sbom master_report.sbom)
              COUNT=$(echo $DIFF | jq 'length')
              if [ "$COUNT" -gt 0 ]; then
                printf "New vulnerabilities found: $COUNT\n"
                jq '.[] | select(.source_id as $a | '"$DIFF"' | index($a))' pr_report.sbom
                exit 1
              else
                echo "No new vulnerabilities found!"
                echo "Individual reports for master and pr have been saved under the Artifacts tab."
                exit 0
              fi
        - persist_to_workspace:
            root: /tmp/repos
            paths:
              - master_report.sbom
        - store_artifacts:
            path: /tmp/repos/master_report.sbom
        - store_artifacts:
            path: /tmp/repos/pr_report.sbom

    update_security_status_badge:
      machine:
        image: ubuntu-2204:2024.08.1
      resource_class: medium
      working_directory: /tmp/repos
      environment:
        SUCCESS_MESSAGE: 'passing'
        SUCCESS_COLOR: 'brightgreen'
        FAILURE_MESSAGE: 'failing'
        FAILURE_COLOR: 'FF0A0A'
        SEVERITY_THRESHOLD: 'CRITICAL'
      steps:
        - attach_workspace:
            at: /tmp/repos
        - add_ssh_keys:
            fingerprints:
              - "SHA256:vtzpWrYBLQAMgZIsEv3Nuc1HeINJXFFtUB+IpSY/AK4"
        - run:
            name: Set up Git user
            command: |
              git config --global user.name "CircleCI Bot"
              git config --global user.email "bot@circleci.com"
        - run:
            name: Count vulnerabilities and update status badge
            command: |
              COUNT=$(jq '[.[] | select(.severity == "$SEVERITY_THRESHOLD")] | length' master_report.sbom)
              cd cbioportal-test
              if [ $COUNT -eq 0 ]; then
                MESSAGE=$SUCCESS_MESSAGE
                COLOR=$SUCCESS_COLOR
              else
                MESSAGE=$FAILURE_MESSAGE
                COLOR=$FAILURE_COLOR
              fi
              jq '.message = $MESSAGE | .color = $COLOR' security-status.json > security-status.json
              git add -A
              git commit -m "Update security status"
              git push

workflows:
    end_to_end_tests:
        jobs:
            - build_backend
            - pull_frontend_codebase
            - install_yarn:
                requires:
                    - pull_frontend_codebase
            - end_to_end_tests_localdb:
                requires:
                    - build_backend
                    - pull_frontend_codebase
                    - install_yarn
    tests:
      jobs:
        - checkout_pr
        - pull_cbioportal_test_codebase
        - pull_cbioportal_frontend_codebase
        - build_image:
            requires:
              - checkout_pr
              - pull_cbioportal_test_codebase
        - push_image:
            context:
              - api-tests
            requires:
              - checkout_pr
              - pull_cbioportal_test_codebase
        - run_api_tests:
            context:
              - api-tests
            requires:
              - build_image
              - pull_cbioportal_frontend_codebase
        - run_security_tests:
            context:
              - docker-scout
            requires:
              - build_image
        - update_security_status_badge:
            requires:
              - run_security_tests